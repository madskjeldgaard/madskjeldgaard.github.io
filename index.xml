<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mads Kjeldgaard</title>
    <link>https://madskjeldgaard.github.io/</link>
    <description>Recent content on Mads Kjeldgaard</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-uk</language>
    <lastBuildDate>Tue, 14 Apr 2020 10:41:44 +0200</lastBuildDate>
    
	<atom:link href="https://madskjeldgaard.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>I Solens Flint 1000 floder</title>
      <link>https://madskjeldgaard.github.io/work/i-solens-flint/</link>
      <pubDate>Sun, 26 Apr 2020 11:06:16 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/work/i-solens-flint/</guid>
      <description>“I solens flint 1000 floder” is an electronic composition by Mads Kjeldgaard comissioned by Notam and Ultima Festival 2019.
It was composed in 7th order ambisonics, partly at NOTAM in Oslo, Norway, and partly at EMS, Stockholm, Sweden, for a 3D audio speaker dome set up in Oslo as part of Ultima Festival 2019.
The title (which is in Danish) can be translated to something along the lines of “In the shard of the sun 1000 rivers”.</description>
    </item>
    
    <item>
      <title>Verdenskvaernen</title>
      <link>https://madskjeldgaard.github.io/work/verdenskvaernen/</link>
      <pubDate>Sun, 26 Apr 2020 11:06:06 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/work/verdenskvaernen/</guid>
      <description>Verdenskværnen (&amp;ldquo;The world grinder&amp;rdquo;) is a composition inspired by the Swedish author August Strindberg&amp;rsquo;s rambling, autobiographical novel &amp;ldquo;Inferno&amp;rdquo; (1898) as well as the sounds of gentrification.
It explores different ideas of sonic tactility in it&amp;rsquo;s sound material.
 &amp;ldquo;The sun shines, everyday life proceeds on its usual course, the cheerful bustle of business raises the spirits. Then one feels rebellious, and challenges heaven with doubts. But when night, silence, and loneliness reign, the heart beats, and the breast suffers from constriction.</description>
    </item>
    
    <item>
      <title>SoX tutorial: SoX on Android</title>
      <link>https://madskjeldgaard.github.io/posts/sox-tutorial-sox-on-android/</link>
      <pubDate>Sun, 26 Apr 2020 10:21:42 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/posts/sox-tutorial-sox-on-android/</guid>
      <description>In this tutorial, I will cover how to install and setup SoX on android devices using Termux.
Termux is a free “Android terminal emulator and Linux environment app that works directly with no rooting or setup required”.
Basically it is a command line interface for your Android device and works like a small linux distribution. It even includes a package management system. And if you get something like an OTG-dongle you can even connect a keyboard and/or a class compliant sound interface.</description>
    </item>
    
    <item>
      <title>SoX tutorial: SoX tutorial: Batch processing audio on the command line</title>
      <link>https://madskjeldgaard.github.io/posts/sox-tutorial-batch-processing/</link>
      <pubDate>Sun, 26 Apr 2020 10:07:25 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/posts/sox-tutorial-batch-processing/</guid>
      <description>To make full use of SoX&amp;rsquo; potential for batch processing we will be using a bit of command line wizardry.
The idea is to put our sox command inside of a for-loop which iterates over all audio files in the folder you are currently in. If you are unsure of what folder your terminal is executing from, you can write pwd to see it&amp;rsquo;s full path and ls to see the folder&amp;rsquo;s contents.</description>
    </item>
    
    <item>
      <title>SoX tutorial: Split by silence</title>
      <link>https://madskjeldgaard.github.io/posts/sox-tutorial-split-by-silence/</link>
      <pubDate>Sun, 26 Apr 2020 01:07:33 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/posts/sox-tutorial-split-by-silence/</guid>
      <description>SoX has a very effective and rather precise way of semi-automatically chopping a sound file into smaller sound files.
Let us say you have a sound file containing many different sounds seperated by a bit of silence in between. It could be a series of drum hits that you have recorded off of a drum machine. To make these sounds easy to use, you most probably need them as seperate sound files so you can load them into a sampler or other software as a sample bank of sorts.</description>
    </item>
    
    <item>
      <title>SoX tutorial: Command line tape music (an introduction)</title>
      <link>https://madskjeldgaard.github.io/posts/sox-tutorial-cli-tape-music/</link>
      <pubDate>Sun, 26 Apr 2020 00:00:44 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/posts/sox-tutorial-cli-tape-music/</guid>
      <description>SoX is a very powerful command line audio processing tool. You can think of it as a sort of command line equivalent of Audacity but with a text based interface that let&amp;rsquo;s you perform powerful audio operations by typing just a few words in your computer&amp;rsquo;s terminal.
I came across SoX via the live coding community where it is a popular tool for chopping sound files (by detecting silence) and batch processing large quantities of audio files (eg.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://madskjeldgaard.github.io/pages/about/</link>
      <pubDate>Tue, 14 Apr 2020 10:41:44 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/pages/about/</guid>
      <description>Bio Mads Kjeldgaard (b. 1988 Horsens, Denmark) is an electronic music composer.
He has studied Electronic Music Composition at the Danish Institute of Electronic Music (DIEM) at the Royal Academy of Music and has a degree in journalism from the Danish School of Media and Journalism.
He works at The Norwegian Center for Arts and Technology (aka Notam) in Oslo and is part of nyMusikk’s Composer Group.
As a developer, he contributes to various open source software projects related to digital art.</description>
    </item>
    
    <item>
      <title>Concerts</title>
      <link>https://madskjeldgaard.github.io/pages/concerts/</link>
      <pubDate>Tue, 14 Apr 2020 10:41:44 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/pages/concerts/</guid>
      <description>Past concerts:
September 20th-21st, Ultima Festival @ Sentralen. World premiere of 3D audio piece &amp;ldquo;I solens flint 1000 floder&amp;rdquo; + ambisonic remixes of classic works of Else Marie Pade, Bernard Parmegiani and Edgar(d) Varése.
June 17th, SCOslo community concert @ Notam.
April 28th, IAC, Malmø, Sweden @ INTONAL Festival. Acousmatic concert with Giuseppe Pisano
March 9th, 2019, Kulturhuset, Oslo, Norway @ Fritt Fall. Livecode / improvisation.
December 6th, 2018, Cappelens Forslag, Oslo, Norway @ Hollow Body Timbals release.</description>
    </item>
    
    <item>
      <title>contact</title>
      <link>https://madskjeldgaard.github.io/pages/contact/</link>
      <pubDate>Tue, 14 Apr 2020 10:41:44 +0200</pubDate>
      
      <guid>https://madskjeldgaard.github.io/pages/contact/</guid>
      <description>Email: mail ☻ madskjeldgaard.dk
Github: madskjeldgaard
Instagram: @mads_kjeldgaard
YouTube: youtube</description>
    </item>
    
    <item>
      <title>NeoVim setup for c&#43;&#43; and openFrameworks development</title>
      <link>https://madskjeldgaard.github.io/neovim-setup-for-c-and-openframeworks-development/</link>
      <pubDate>Mon, 06 Apr 2020 15:44:23 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/neovim-setup-for-c-and-openframeworks-development/</guid>
      <description>It is possible to get a nice development environment on Linux (and other platforms) using NeoVim and a few plugins and settings.
This dev environment includes snippets, autocomplete, debugging and smart code suggestions for methods.
I got a lot of pointers for this setup from Chendi Xue’s blogpost about Vim/CPP development.
So, without further ado here are my notes for setting up shop using YouCompleteMe, UltiSnips and some formatting plugins.</description>
    </item>
    
    <item>
      <title>How to generate SuperCollider files containing random patterns</title>
      <link>https://madskjeldgaard.github.io/how-to-generate-supercollider-files-containing-random-patterns/</link>
      <pubDate>Sun, 01 Mar 2020 13:50:52 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/how-to-generate-supercollider-files-containing-random-patterns/</guid>
      <description>Today I tested out this simple but powerful idea: To generate SuperCollider files containing small generative compositions. The idea is to at some point use this to save the states of generative patterns that I am working on in real time.
See this gist for a code example.</description>
    </item>
    
    <item>
      <title>SuperCollider workshop at Notam, january 2020: Algorithmic composition using patterns</title>
      <link>https://madskjeldgaard.github.io/supercollider-workshop-at-notam-january-2020-algorithmic-composition-using-patterns/</link>
      <pubDate>Thu, 23 Jan 2020 21:18:29 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/supercollider-workshop-at-notam-january-2020-algorithmic-composition-using-patterns/</guid>
      <description>Here are the slides for the SuperCollider workshop at Notam, january 2020.
Download slides</description>
    </item>
    
    <item>
      <title>Pattern workshop, Herlev Bibliotek 2019</title>
      <link>https://madskjeldgaard.github.io/pattern-workshop-herlev-bibliotek-2019/</link>
      <pubDate>Wed, 06 Nov 2019 11:22:54 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/pattern-workshop-herlev-bibliotek-2019/</guid>
      <description>Here are the materials for the SuperCollider workshop at Herlev Bibliotek, Denmark, November 2019.
The SynthDef used for the workshop can be downloaded here.
Download slides here.</description>
    </item>
    
    <item>
      <title>How to change the default synth in SuperCollider</title>
      <link>https://madskjeldgaard.github.io/how-to-change-the-default-synth-in-supercollider/</link>
      <pubDate>Fri, 18 Oct 2019 12:42:12 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/how-to-change-the-default-synth-in-supercollider/</guid>
      <description>The default synth sound in SuperCollider is a cheesy old piano sound. If you have ever tried the event pattern examples in the documentation of SuperCollider or been in the process of testing some pattern specifics of your own, you will have heard this extremely unconvincing synthesizer:
A nice alternative: A triangle wave synth with a low pass filter Imagine a utopian world where the default cheese-piano-synth has been replaced by a nicer, kind of gameboy like synth.</description>
    </item>
    
    <item>
      <title>Introduction to SuperCollider, Notam 2019</title>
      <link>https://madskjeldgaard.github.io/scintro-notam-2019/</link>
      <pubDate>Sun, 01 Sep 2019 12:54:46 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/scintro-notam-2019/</guid>
      <description>Here you will find the material for the introductory workshop held at Notam, Oslo in late summer 2019.
The slides may be used as a sort of cheatsheet as well as notes for remembering the topics covered:
• An overview: What is SuperCollider and what can you do with it?
• The design and architecture of SuperCollider
• Language basics: syntax, variables, expressions and functions
• Learning resources: How to proceed from here</description>
    </item>
    
    <item>
      <title>Ambisonics tutorial: Binaural head rotation using Reaper, Hedrot and IEM Plugins</title>
      <link>https://madskjeldgaard.github.io/ambisonics-tutorial-binaural-head-rotation-using-reaper-hedrot-and-iem-plugins/</link>
      <pubDate>Thu, 22 Aug 2019 08:56:36 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/ambisonics-tutorial-binaural-head-rotation-using-reaper-hedrot-and-iem-plugins/</guid>
      <description>Hedrot is an inexpensive head rotator that you can build yourself and attach to any pair of head phones, based on a small microcontroller (a Teensy) with an attached sensor board that measures your head’s rotation, pitch, tilt, etc.
Using the Hedrot, you can monitor a binaural version of an ambisonic mix in a pair of headphones and be able to move your head around inside the sound field.
In this tutorial we will cover how to set up the Hedrot application to send it’s sensor data via OSC to Reaper to rotate our ambisonic mix with our head movements.</description>
    </item>
    
    <item>
      <title>SuperCollider tutorial: Mass producing SynthDefs</title>
      <link>https://madskjeldgaard.github.io/supercollider-tutorial-mass-producing-synthdefs/</link>
      <pubDate>Mon, 19 Aug 2019 10:36:35 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/supercollider-tutorial-mass-producing-synthdefs/</guid>
      <description>In SuperCollider, one of the most common ways of making sounds is by first defining a sort of recipe for a UGEN patch in a SynthDef and then from that recipe produce Synths that make sounds.
But when you write a SynthDef, the patch architecture cannot change after the definition (as opposed to changing arguments in the patch).
This becomes annoying when working with UGens that want to know the exact number of channels used, eg.</description>
    </item>
    
    <item>
      <title>SuperCollider tutorial: Easily render generative compositions as sound files using NRT</title>
      <link>https://madskjeldgaard.github.io/supercollider-how-to-render-patterns-as-sound-files-using-nrt/</link>
      <pubDate>Mon, 05 Aug 2019 17:46:09 +0000</pubDate>
      
      <guid>https://madskjeldgaard.github.io/supercollider-how-to-render-patterns-as-sound-files-using-nrt/</guid>
      <description>One of the many powerful features of SuperCollider is it’s ability to render sounds offline. This is called Non-Realtime Synthesis (NRT). NRT is for example useful for fast, offline processing of sounds, doing sound analysis or rendering generative compositions.
NRT works like this (normally): First you write a list of server OSC messages (stored in a Score usually) which will tell the (offline) server what to do at what point in time when you decide to render it.</description>
    </item>
    
  </channel>
</rss>